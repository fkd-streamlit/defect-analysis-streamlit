# -*- coding: utf-8 -*-
# app.py : å°„å‡ºæˆå½¢ææ–™æ–­é¢ã®çµæ™¶ç²’å¾„è§£æï¼ˆStreamlit ç‰ˆï¼‰
# Author: ç¦ç”°ã•ã‚“å‘ã‘ æ”¹å–„ç‰ˆï¼ˆãƒ­ãƒ¼ã‚«ãƒ«/VSCode å®Ÿè¡Œæƒ³å®šï¼‰
#
# === ã“ã®ç‰ˆã®ãƒã‚¤ãƒ³ãƒˆ ===
# 1) æ¤œå‡ºå¯¾è±¡ã‚’åˆ‡æ›¿å¯èƒ½ï¼š
#    - ç™½é ˜åŸŸï¼ˆææ–™/ç²’å­ï¼‰
#    - é»’é ˜åŸŸï¼ˆæ¬ é™¥ï¼‰ï¼š
#         a) äºŒå€¤ã®é»’ï¼ˆå†…éƒ¨ç©´ï¼‰æ–¹å¼ï¼ˆå¾“æ¥ï¼‰
#         b) å…ƒç”»åƒã®æ·±ã„é»’ç‚¹ï¼ˆãƒ–ãƒ©ãƒƒã‚¯ãƒãƒƒãƒˆï¼‰æ–¹å¼ï¼ˆNEWï¼‰
# 2) æ¬ é™¥ãƒã‚¹ã‚¯ç”¨Open/Closeï¼ˆã‚µã‚¤ãƒ‰ãƒãƒ¼èª¿æ•´ï¼‰
# 3) ã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤è¼ªéƒ­ï¼èµ¤ï¼ˆå¤ªã•èª¿æ•´ã€è¼ªéƒ­ã®ã¿è¡¨ç¤ºå¯ï¼‰
# 4) æ¬ é™¥ç‡ï¼ˆAæ¡ˆï¼‰ï¼šæ¬ é™¥ç·é¢ç© / ææ–™é¢ç©ï¼ˆ%ï¼‰ã‚’ç”»é¢è¡¨ç¤ºï¼‹CSVå‡ºåŠ›
# 5) use_container_width çµ±ä¸€
# 6) Watershed min_distance ã‚’ãƒ”ãƒ¼ã‚¯æŠ½å‡ºã«åæ˜ 

import io
import os
import zipfile
import tempfile
from typing import List, Tuple, Dict, Optional

import numpy as np
import pandas as pd
import cv2
import streamlit as st
import matplotlib
import matplotlib.pyplot as plt
from matplotlib import font_manager
from skimage import measure, morphology, segmentation, exposure, util
from skimage.feature import peak_local_max
from scipy import ndimage as ndi


# =========================================================
# æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆè¨­å®šï¼ˆæ–‡å­—åŒ–ã‘å¯¾ç­–ï¼‰ï¼‹è¦‹ãŸç›®
# Streamlit Cloud å¯¾å¿œï¼šfonts/ ã«åŒæ¢±ã—ãŸãƒ•ã‚©ãƒ³ãƒˆã‚’å„ªå…ˆçš„ã«ä½¿ç”¨
# =========================================================
def setup_japanese_font_and_style():
    import os
    from matplotlib import font_manager
    import matplotlib

    # 1) ãƒªãƒã‚¸ãƒˆãƒªåŒæ¢±ãƒ•ã‚©ãƒ³ãƒˆï¼ˆæœ€å„ªå…ˆï¼‰
    #   fonts/NotoSansJP-Regular.otf ãªã©ã‚’ç½®ãæƒ³å®š
    local_font_candidates = [
        os.path.join("fonts", "NotoSansJP-Regular.otf"),
        os.path.join("fonts", "NotoSansJP-Regular.ttf"),
        os.path.join("fonts", "NotoSansCJKjp-Regular.otf"),
        os.path.join("fonts", "NotoSansCJKjp-Regular.ttf"),
    ]

    for fp in local_font_candidates:
        if os.path.exists(fp):
            try:
                font_manager.fontManager.addfont(fp)
                prop = font_manager.FontProperties(fname=fp)
                matplotlib.rcParams["font.family"] = prop.get_name()
                break
            except Exception:
                pass

    # 2) OSã«å…¥ã£ã¦ã„ã‚‹ãƒ•ã‚©ãƒ³ãƒˆã‹ã‚‰æ¢ã™ï¼ˆãƒ­ãƒ¼ã‚«ãƒ«Windowså‘ã‘ï¼‰
    if matplotlib.rcParams.get("font.family", None) is None or matplotlib.rcParams["font.family"] in [None, "sans-serif"]:
        candidates = [
            "Yu Gothic", "Yu Gothic UI",
            "Meiryo", "Meiryo UI",
            "MS Gothic", "MS PGothic",
            "BIZ UDã‚´ã‚·ãƒƒã‚¯", "BIZ UDPGothic",
            "Noto Sans CJK JP", "Noto Sans JP",
        ]
        available = {f.name for f in font_manager.fontManager.ttflist}
        for name in candidates:
            if name in available:
                matplotlib.rcParams["font.family"] = name
                break

    # 3) ä½“è£ï¼ˆå…±é€šï¼‰
    matplotlib.rcParams["axes.unicode_minus"] = False
    matplotlib.rcParams["font.size"] = 9
    matplotlib.rcParams["axes.titlesize"] = 10
    matplotlib.rcParams["axes.labelsize"] = 9
    matplotlib.rcParams["xtick.labelsize"] = 8
    matplotlib.rcParams["ytick.labelsize"] = 8
    matplotlib.rcParams["legend.fontsize"] = 8
    matplotlib.rcParams["figure.autolayout"] = False
    matplotlib.rcParams["lines.linewidth"] = 1.5


# =========================================================
# å…±é€šãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
# =========================================================
def read_image_from_bytes(file_bytes: bytes) -> np.ndarray:
    file_arr = np.frombuffer(file_bytes, dtype=np.uint8)
    img = cv2.imdecode(file_arr, cv2.IMREAD_UNCHANGED)
    if img is None:
        raise ValueError("ç”»åƒã®ãƒ‡ã‚³ãƒ¼ãƒ‰ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ãƒ•ã‚¡ã‚¤ãƒ«ãŒå£Šã‚Œã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")
    if img.ndim == 3:
        img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    else:
        img_gray = img
    return img_gray


def compute_um_per_px(um_per_px: float,
                      scalebar_um: Optional[float],
                      scalebar_px: Optional[float]) -> float:
    if (scalebar_um and scalebar_px) and scalebar_px > 0:
        return float(scalebar_um) / float(scalebar_px)
    return float(um_per_px)


def apply_preprocess(img_gray: np.ndarray,
                     clip_limit: float,
                     gaussian_ksize: int,
                     gaussian_sigma: float) -> np.ndarray:
    # å±€æ‰€ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆå¼·èª¿ï¼ˆãƒ ãƒ©è£œæ­£ï¼‰â†’äºŒå€¤åŒ–ã‚„æš—ç‚¹æŠ½å‡ºã®åŠ©ã‘
    img_eq = exposure.equalize_adapthist(img_gray, clip_limit=clip_limit)
    img8 = util.img_as_ubyte(img_eq)
    if gaussian_ksize > 0 and gaussian_ksize % 2 == 1:
        img8 = cv2.GaussianBlur(img8, (gaussian_ksize, gaussian_ksize), gaussian_sigma)
    return img8


def binarize(img: np.ndarray,
             method: str,
             manual_thresh: int,
             adaptive_block: int,
             adaptive_C: int) -> np.ndarray:
    """
    å‡ºåŠ›: 0/255 uint8
    THRESH_BINARY_INV: æš—ã„éƒ¨åˆ†ã‚’ç™½ã«ã™ã‚‹
    """
    if method == "otsu":
        thr, _ = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
        _, bin_img = cv2.threshold(img, thr, 255, cv2.THRESH_BINARY_INV)
    elif method == "adaptive":
        block = max(3, adaptive_block | 1)
        bin_img = cv2.adaptiveThreshold(
            img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
            cv2.THRESH_BINARY_INV, blockSize=block, C=adaptive_C
        )
    else:
        _, bin_img = cv2.threshold(img, manual_thresh, 255, cv2.THRESH_BINARY_INV)
    return bin_img


def morph_cleanup(bin_img: np.ndarray,
                  open_ksize: int, open_iter: int,
                  close_ksize: int, close_iter: int) -> np.ndarray:
    out = bin_img.copy()
    if open_ksize > 0 and open_iter > 0:
        k_open = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (open_ksize, open_ksize))
        out = cv2.morphologyEx(out, cv2.MORPH_OPEN, k_open, iterations=open_iter)
    if close_ksize > 0 and close_iter > 0:
        k_close = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (close_ksize, close_ksize))
        out = cv2.morphologyEx(out, cv2.MORPH_CLOSE, k_close, iterations=close_iter)
    return out


# =========================================================
# ææ–™ãƒã‚¹ã‚¯ï¼ˆæœ€å¤§é€£çµæˆåˆ†ï¼‰
# =========================================================
def largest_component_mask(bin_u8: np.ndarray) -> np.ndarray:
    lab = measure.label(bin_u8 > 0, connectivity=2)
    if lab.max() == 0:
        return np.zeros_like(bin_u8, dtype=bool)
    props = measure.regionprops(lab)
    largest = max(props, key=lambda p: p.area)
    return lab == largest.label


# =========================================================
# æ¬ é™¥æŠ½å‡ºï¼ˆé»’é ˜åŸŸï¼‰
#   (A) äºŒå€¤ã®é»’ï¼ˆå†…éƒ¨ç©´ï¼‰æ–¹å¼
# =========================================================
def extract_internal_black_defects(bin_clean_u8: np.ndarray,
                                   assume_material_is_largest: bool = True) -> np.ndarray:
    if assume_material_is_largest:
        material = largest_component_mask(bin_clean_u8)
    else:
        material = (bin_clean_u8 > 0)

    filled = ndi.binary_fill_holes(material)
    holes = filled & (~material)
    return (holes.astype(np.uint8) * 255)


# =========================================================
# æ¬ é™¥æŠ½å‡ºï¼ˆé»’é ˜åŸŸï¼‰
#   (B) å…ƒç”»åƒã®æ·±ã„é»’ç‚¹ï¼ˆãƒ–ãƒ©ãƒƒã‚¯ãƒãƒƒãƒˆï¼‰æ–¹å¼ï¼ˆNEWï¼‰
# =========================================================
def extract_dark_spots_blackhat(img_u8: np.ndarray,
                                material_mask_u8: np.ndarray,
                                bh_ksize: int,
                                thresh_mode: str,
                                manual_thr: int,
                                border_exclude_px: int = 0) -> Tuple[np.ndarray, np.ndarray]:
    """
    - img_u8: å…ƒç”»åƒ(0-255) ã¾ãŸã¯å‰å‡¦ç†å¾Œç”»åƒ
    - material_mask_u8: 0/255 ææ–™é ˜åŸŸãƒã‚¹ã‚¯ï¼ˆèƒŒæ™¯é™¤å¤–ï¼‰
    - bh_ksize: ãƒ–ãƒ©ãƒƒã‚¯ãƒãƒƒãƒˆã®ã‚«ãƒ¼ãƒãƒ«ã‚µã‚¤ã‚ºï¼ˆæ¬ é™¥ã‚ˆã‚Šå°‘ã—å¤§ããï¼‰
    - thresh_mode: 'otsu' or 'manual'
    - manual_thr: æ‰‹å‹•ã—ãã„å€¤
    - border_exclude_px: ææ–™å¢ƒç•Œè¿‘å‚ã‚’é™¤å¤–ï¼ˆå½±/ç¸ã®å½æ¤œå‡ºå¯¾ç­–ï¼‰

    return:
      defect_mask_u8 (0/255), blackhat_u8 (0/255ç›¸å½“ã®å¼·èª¿ç”»åƒ)
    """
    # ææ–™å¢ƒç•Œã®é™¤å¤–ï¼ˆä»»æ„ï¼‰
    mat = (material_mask_u8 > 0).astype(np.uint8) * 255
    if border_exclude_px > 0:
        k = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (2*border_exclude_px+1, 2*border_exclude_px+1))
        mat = cv2.erode(mat, k, iterations=1)

    # ãƒ–ãƒ©ãƒƒã‚¯ãƒãƒƒãƒˆï¼šæš—ç‚¹ã‚’å¼·èª¿
    ksz = max(3, int(bh_ksize) | 1)  # å¥‡æ•°åŒ–
    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (ksz, ksz))
    blackhat = cv2.morphologyEx(img_u8, cv2.MORPH_BLACKHAT, kernel)

    # ææ–™é ˜åŸŸã ã‘ã«é™å®š
    blackhat_roi = cv2.bitwise_and(blackhat, blackhat, mask=mat)

    # äºŒå€¤åŒ–
    if thresh_mode == "otsu":
        # Otsuã¯èƒŒæ™¯ãŒå°‘ãªã„ROIã§ã‚‚åŠ¹ããŒã€çŠ¶æ³ã«ã‚ˆã‚Šéå‰°/éå°ãŒã‚ã‚Šå¾—ã‚‹
        thr, defect = cv2.threshold(blackhat_roi, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
    else:
        thr = int(manual_thr)
        _, defect = cv2.threshold(blackhat_roi, thr, 255, cv2.THRESH_BINARY)

    return defect, blackhat_roi


# =========================================================
# æ¬ é™¥ç‡ï¼ˆAæ¡ˆï¼‰ï¼šæ¬ é™¥ç·é¢ç© / ææ–™é¢ç©
# =========================================================
def compute_area_stats_A(bin_clean_u8: np.ndarray,
                         defect_mask_u8: np.ndarray,
                         um_per_px: float,
                         assume_material_is_largest: bool = True) -> Dict[str, float]:
    if assume_material_is_largest:
        material_mask = largest_component_mask(bin_clean_u8)
    else:
        material_mask = (bin_clean_u8 > 0)

    material_area_px = float(np.count_nonzero(material_mask))
    defect_area_px = float(np.count_nonzero(defect_mask_u8 > 0))

    material_area_um2 = material_area_px * (um_per_px ** 2)
    defect_area_um2 = defect_area_px * (um_per_px ** 2)

    defect_ratio_percent = (defect_area_px / (material_area_px + 1e-9)) * 100.0

    return {
        "material_area_px": material_area_px,
        "defect_area_px": defect_area_px,
        "material_area_um2": material_area_um2,
        "defect_area_um2": defect_area_um2,
        "defect_ratio_percent": defect_ratio_percent
    }


# =========================================================
# Watershed
# =========================================================
def split_touching_particles(bin_u8: np.ndarray,
                             min_distance_px: int,
                             h_max: float) -> np.ndarray:
    mask = (bin_u8 > 0)
    distance = ndi.distance_transform_edt(mask)

    if h_max > 0:
        _ = morphology.h_maxima(distance, h=h_max)

    coords = peak_local_max(
        distance,
        min_distance=max(1, int(min_distance_px)),
        labels=mask,
        exclude_border=False
    )

    markers = np.zeros_like(distance, dtype=np.int32)
    if coords.size > 0:
        for i, (r, c) in enumerate(coords, start=1):
            markers[r, c] = i
    else:
        markers = measure.label(mask, connectivity=2).astype(np.int32)

    labels = segmentation.watershed(-distance, markers, mask=mask)
    return labels


def label_by_connected_components(bin_u8: np.ndarray) -> np.ndarray:
    return measure.label(bin_u8 > 0, connectivity=2)


# =========================================================
# è¨ˆæ¸¬
# =========================================================
def min_area_rect_feret(coords_rc: np.ndarray) -> Tuple[float, float, float]:
    pts = np.fliplr(coords_rc).astype(np.float32)
    if len(pts) < 5:
        x_min, y_min = pts[:, 0].min(), pts[:, 1].min()
        x_max, y_max = pts[:, 0].max(), pts[:, 1].max()
        w, h = (x_max - x_min), (y_max - y_min)
        feret_max, feret_min, angle = (max(w, h), min(w, h), 0.0)
    else:
        rect = cv2.minAreaRect(pts)
        (_, _), (w, h), angle = rect
        feret_max, feret_min = (max(w, h), min(w, h))
    return float(feret_max), float(feret_min), float(angle)


def extract_region_metrics(label_img: np.ndarray,
                           um_per_px: float,
                           exclude_largest: bool,
                           min_area_px: int,
                           min_area_um2: float) -> pd.DataFrame:
    props = measure.regionprops(label_img)
    if len(props) == 0:
        return pd.DataFrame()

    largest_label = None
    if exclude_largest:
        largest = max(props, key=lambda p: p.area)
        largest_label = largest.label

    rows = []
    for p in props:
        if largest_label and p.label == largest_label:
            continue

        area_px = float(p.area)
        area_um2 = area_px * (um_per_px ** 2)

        if area_px < max(0, min_area_px):
            continue
        if min_area_um2 > 0 and area_um2 < min_area_um2:
            continue

        ecd_px = float(p.equivalent_diameter)
        maj_px = float(getattr(p, "major_axis_length", 0.0))
        min_px = float(getattr(p, "minor_axis_length", 0.0))
        per_px = float(getattr(p, "perimeter", 0.0))
        cy, cx = p.centroid

        circularity = 4.0 * np.pi * area_px / (per_px ** 2 + 1e-9) if per_px > 0 else np.nan
        feret_max_px, feret_min_px, _ = min_area_rect_feret(p.coords)
        aspect = (maj_px / (min_px + 1e-9)) if (maj_px > 0 and min_px > 0) else np.nan

        rows.append({
            "label": int(p.label),
            "area_px": area_px,
            "perimeter_px": per_px,
            "equiv_diam_px": ecd_px,
            "major_axis_px": maj_px,
            "minor_axis_px": min_px,
            "aspect_ratio": aspect,
            "circularity": circularity,
            "feret_max_px": feret_max_px,
            "feret_min_px": feret_min_px,
            "orientation_deg": float(np.rad2deg(getattr(p, "orientation", 0.0))),
            "centroid_x_px": float(cx),
            "centroid_y_px": float(cy),

            "equiv_diam_um": ecd_px * um_per_px,
            "major_axis_um": maj_px * um_per_px,
            "minor_axis_um": min_px * um_per_px,
            "feret_max_um": feret_max_px * um_per_px,
            "feret_min_um": feret_min_px * um_per_px,
            "area_um2": area_um2,
        })

    df = pd.DataFrame(rows)
    if not df.empty:
        df.sort_values("area_px", ascending=False, inplace=True, ignore_index=True)
        df.insert(0, "particle_id", np.arange(1, len(df) + 1))
    return df


# =========================================================
# ã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤ï¼ˆè¼ªéƒ­ï¼èµ¤ï¼‰
# =========================================================
def overlay_labels(img_gray: np.ndarray,
                   label_img: np.ndarray,
                   df: pd.DataFrame,
                   aspect_bins: Tuple[float, float] = (2.0, 3.0),
                   show_id: bool = True,
                   fill_alpha: float = 0.25,
                   draw_red_contour: bool = True,
                   contour_thickness: int = 3,
                   contour_only: bool = False) -> np.ndarray:

    img_color = cv2.cvtColor(img_gray, cv2.COLOR_GRAY2BGR)
    if df.empty:
        return img_color

    low, high = aspect_bins

    keep_labels = df["label"].astype(int).values
    keep_mask = np.isin(label_img, keep_labels)
    label_keep = label_img.copy()
    label_keep[~keep_mask] = 0

    # å¡—ã‚Šã¤ã¶ã—ï¼ˆä»»æ„ï¼‰
    if not contour_only:
        a = float(np.clip(fill_alpha, 0.0, 1.0))
        for _, row in df.iterrows():
            lbl = int(row["label"])
            mask = (label_img == lbl)
            aspect = row["aspect_ratio"]

            if np.isnan(aspect):
                color = (200, 200, 200)
            elif aspect > high:
                color = (0, 0, 255)
            elif aspect > low:
                color = (0, 255, 255)
            else:
                color = (0, 200, 0)

            ys, xs = np.where(mask)
            if len(xs) == 0:
                continue
            img_color[ys, xs] = ((1 - a) * img_color[ys, xs] + a * np.array(color)).astype(np.uint8)

    # è¼ªéƒ­ï¼èµ¤
    if draw_red_contour:
        boundary = segmentation.find_boundaries(label_keep, mode="outer")
        bnd = (boundary.astype(np.uint8) * 255)

        t = max(1, int(contour_thickness))
        if t > 1:
            k = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (2 * t + 1, 2 * t + 1))
            bnd = cv2.dilate(bnd, k, iterations=1)

        ys, xs = np.where(bnd > 0)
        img_color[ys, xs] = (0, 0, 255)

    # IDè¡¨ç¤º
    if show_id:
        for _, row in df.iterrows():
            cx, cy = int(row["centroid_x_px"]), int(row["centroid_y_px"])
            cv2.putText(img_color, str(int(row["particle_id"])),
                        (cx, cy), cv2.FONT_HERSHEY_SIMPLEX, 0.4,
                        (255, 255, 255), 1, cv2.LINE_AA)

    return img_color


# =========================================================
# çµ±è¨ˆãƒ—ãƒ­ãƒƒãƒˆ
# =========================================================
def plot_distributions(df: pd.DataFrame, xcols: List[str], group: Optional[str] = None):
    if df.empty:
        st.info("æœ‰åŠ¹ãªç²’å­ãŒã‚ã‚Šã¾ã›ã‚“ã€‚ã—ãã„å€¤ãƒ»é¢ç©ãƒ•ã‚£ãƒ«ã‚¿ã‚’èª¿æ•´ã—ã¦ãã ã•ã„ã€‚")
        return

    FIGSIZE = (3.5, 2.6)
    DPI = 110

    for x in xcols:
        st.markdown(f"### æŒ‡æ¨™ï¼š**{x}**")
        col1, col2 = st.columns(2)

        with col1:
            fig, ax = plt.subplots(figsize=FIGSIZE, dpi=DPI)
            if group and group in df.columns:
                for g, d in df.groupby(group):
                    ax.hist(d[x].dropna(), bins=30, alpha=0.5, label=str(g))
                ax.legend()
            else:
                ax.hist(df[x].dropna(), bins=30, color="steelblue", edgecolor="black")
            ax.grid(alpha=0.3)
            ax.set_xlabel(x)
            ax.set_ylabel("é »åº¦")
            fig.tight_layout()
            st.pyplot(fig, clear_figure=True)

        with col2:
            fig2, ax2 = plt.subplots(figsize=FIGSIZE, dpi=DPI)
            if group and group in df.columns:
                df.boxplot(column=x, by=group, ax=ax2, rot=45)
                ax2.set_title(f"{x}ï¼ˆgroupåˆ¥ï¼‰")
                fig2.suptitle("")
            else:
                df[[x]].boxplot(ax=ax2, vert=True)
                ax2.set_title(x)
            ax2.grid(alpha=0.3)
            fig2.tight_layout()
            st.pyplot(fig2, clear_figure=True)

        st.markdown("#### CDFï¼ˆç´¯ç©åˆ†å¸ƒï¼‰")
        fig3, ax3 = plt.subplots(figsize=(7, 2.4), dpi=DPI)
        d = df[x].dropna().sort_values()
        if len(d) > 0:
            cdf = np.arange(1, len(d) + 1) / len(d)
            ax3.plot(d, cdf, color="tomato")
        ax3.set_xlabel(x)
        ax3.set_ylabel("ç´¯ç©ç¢ºç‡")
        ax3.grid(alpha=0.3)
        fig3.tight_layout()
        st.pyplot(fig3, clear_figure=True)


# =========================================================
# ç”»åƒ1æšå‡¦ç†
# =========================================================
def process_one_image(name: str,
                      file_bytes: bytes,
                      um_per_px: float,
                      threshold_method: str,
                      manual_thresh: int,
                      adaptive_block: int,
                      adaptive_C: int,
                      clahe_clip: float,
                      gauss_ksize: int,
                      gauss_sigma: float,
                      open_ksize: int, open_iter: int,
                      close_ksize: int, close_iter: int,
                      # æ¬ é™¥ãƒã‚¹ã‚¯ç”¨å¾Œå‡¦ç†
                      defect_open_ksize: int, defect_open_iter: int,
                      defect_close_ksize: int, defect_close_iter: int,
                      # å¯¾è±¡åˆ‡æ›¿
                      target_mode: str,
                      assume_material_is_largest: bool,
                      defect_mode_black: str,
                      # Blackhatè¨­å®š
                      bh_use_preprocessed: bool,
                      bh_ksize: int,
                      bh_thresh_mode: str,
                      bh_manual_thr: int,
                      bh_border_exclude: int,
                      # ãƒ©ãƒ™ãƒªãƒ³ã‚°
                      use_watershed: bool,
                      min_distance_px: int,
                      h_max: float,
                      # ãƒ•ã‚£ãƒ«ã‚¿ç­‰
                      exclude_largest: bool,
                      min_area_px: int,
                      min_area_um2: float,
                      # overlay
                      aspect_bins: Tuple[float, float],
                      show_id: bool,
                      fill_alpha: float,
                      draw_red_contour: bool,
                      contour_thickness: int,
                      contour_only: bool
                      ) -> Tuple[pd.DataFrame, np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray]:

    img_gray = read_image_from_bytes(file_bytes)
    img_pre = apply_preprocess(img_gray, clahe_clip, gauss_ksize, gauss_sigma)

    # ææ–™ãƒã‚¹ã‚¯ç”¨é€”ã«ã‚‚ä½¿ã†ã€ŒäºŒå€¤ï¼ˆå¾Œå‡¦ç†è¾¼ã¿ï¼‰ã€ã‚’å¸¸ã«ä½œã‚‹
    bin_img = binarize(img_pre, threshold_method, manual_thresh, adaptive_block, adaptive_C)
    bin_clean = morph_cleanup(bin_img, open_ksize, open_iter, close_ksize, close_iter)

    debug_bh = np.zeros_like(img_gray, dtype=np.uint8)

    # --- è§£æå¯¾è±¡ã®åˆ‡æ›¿ ---
    if target_mode == "é»’é ˜åŸŸï¼ˆæ¬ é™¥ï¼‰":
        # ææ–™é ˜åŸŸï¼ˆèƒŒæ™¯é™¤å¤–ï¼‰ãƒã‚¹ã‚¯ï¼šbin_clean ã‹ã‚‰æœ€å¤§é€£çµæˆåˆ†
        material_mask_u8 = (largest_component_mask(bin_clean).astype(np.uint8) * 255)

        if defect_mode_black == "äºŒå€¤ã®é»’ï¼ˆå†…éƒ¨ç©´ï¼‰":
            defect_mask = extract_internal_black_defects(
                bin_clean,
                assume_material_is_largest=assume_material_is_largest
            )
            debug_bh = np.zeros_like(img_gray, dtype=np.uint8)

        else:
            # å…ƒç”»åƒã®æ·±ã„é»’ç‚¹ï¼ˆãƒ–ãƒ©ãƒƒã‚¯ãƒãƒƒãƒˆï¼‰
            img_used = img_pre if bh_use_preprocessed else img_gray
            defect_mask, debug_bh = extract_dark_spots_blackhat(
                img_u8=img_used.astype(np.uint8),
                material_mask_u8=material_mask_u8,
                bh_ksize=bh_ksize,
                thresh_mode=bh_thresh_mode,
                manual_thr=bh_manual_thr,
                border_exclude_px=bh_border_exclude
            )

        # æ¬ é™¥ãƒã‚¹ã‚¯å¾Œå‡¦ç†ï¼ˆãƒã‚¤ã‚ºé™¤å»ï¼‰
        defect_mask = morph_cleanup(
            defect_mask,
            defect_open_ksize, defect_open_iter,
            defect_close_ksize, defect_close_iter
        )

        bin_target = defect_mask

    else:
        # ç™½é ˜åŸŸï¼ˆææ–™/ç²’å­ï¼‰
        bin_target = bin_clean
        debug_bh = np.zeros_like(img_gray, dtype=np.uint8)

    # --- ãƒ©ãƒ™ãƒªãƒ³ã‚° ---
    if use_watershed:
        label_img = split_touching_particles(bin_target, min_distance_px, h_max)
    else:
        label_img = label_by_connected_components(bin_target)

    # --- è¨ˆæ¸¬ ---
    df = extract_region_metrics(label_img, um_per_px, exclude_largest, min_area_px, min_area_um2)
    if not df.empty:
        df.insert(0, "source", name)
        df.insert(1, "target_mode", target_mode)
        if target_mode == "é»’é ˜åŸŸï¼ˆæ¬ é™¥ï¼‰":
            df.insert(2, "defect_mode", defect_mode_black)

    # --- overlay ---
    overlay = overlay_labels(
        img_gray, label_img, df, aspect_bins,
        show_id=show_id,
        fill_alpha=fill_alpha,
        draw_red_contour=draw_red_contour,
        contour_thickness=contour_thickness,
        contour_only=contour_only
    ) if not df.empty else cv2.cvtColor(img_gray, cv2.COLOR_GRAY2BGR)

    return df, img_gray, bin_clean, bin_target, debug_bh, overlay


# =========================================================
# Streamlit UI
# =========================================================
st.set_page_config(page_title="æ¬ é™¥ï¼ˆç©ºéš™ï¼‰è§£æï¼ˆStreamlitï¼‰", layout="wide")
st.title("å°„å‡ºæˆå½¢ææ–™æ–­é¢ã®æ¬ é™¥ï¼ˆç©ºéš™ï¼‰è§£æ")
st.caption("é»’æ¬ é™¥ï¼šäºŒå€¤ã®ç©´æ–¹å¼ï¼å…ƒç”»åƒã®æ·±ã„é»’ç‚¹ï¼ˆãƒ–ãƒ©ãƒƒã‚¯ãƒãƒƒãƒˆï¼‰æ–¹å¼ã®ä¸¡å¯¾å¿œã€‚æ¬ é™¥ç‡(Aæ¡ˆ)ã‚‚ç®—å‡ºã€‚")

with st.sidebar:
    st.header("è§£æè¨­å®š")

    st.subheader("ã‚¹ã‚±ãƒ¼ãƒ«è¨­å®š")
    col_scale = st.columns(2)
    with col_scale[0]:
        um_per_px_input = st.number_input("Î¼m / pxï¼ˆç›´æ¥ï¼‰", min_value=0.0, value=1.0, step=0.01, format="%.4f")
    with col_scale[1]:
        st.caption("ã¾ãŸã¯ã‚¹ã‚±ãƒ¼ãƒ«ãƒãƒ¼ã‹ã‚‰ç®—å‡º")
        scalebar_um = st.number_input("ã‚¹ã‚±ãƒ¼ãƒ«ãƒãƒ¼é•· [Î¼m]", min_value=0.0, value=0.0, step=1.0)
        scalebar_px = st.number_input("ã‚¹ã‚±ãƒ¼ãƒ«ãƒãƒ¼é•· [px]", min_value=0.0, value=0.0, step=1.0)

    um_per_px = compute_um_per_px(
        um_per_px_input,
        None if scalebar_um == 0 else scalebar_um,
        None if scalebar_px == 0 else scalebar_px
    )

    st.subheader("å‰å‡¦ç†ï¼ˆã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆï¼‰")
    clahe_clip = st.slider("CLAHE ã‚¯ãƒªãƒƒãƒ—åˆ¶é™", 0.001, 0.050, 0.030, step=0.001)
    gauss_ksize = st.select_slider("Gaussian ksize(å¥‡æ•°)", options=[0, 3, 5, 7, 9], value=5)
    gauss_sigma = st.slider("Gaussian Ïƒ", 0.0, 5.0, 0.0, 0.1)

    st.subheader("äºŒå€¤åŒ–ï¼ˆææ–™ãƒã‚¹ã‚¯ã®å®‰å®šåŒ–ã«ã‚‚åˆ©ç”¨ï¼‰")
    method = st.selectbox("äºŒå€¤åŒ–æ–¹æ³•", ["otsu", "adaptive", "manual"], index=0)
    manual_thresh = st.slider("æ‰‹å‹•ã—ãã„å€¤ï¼ˆmanualæ™‚ï¼‰", 0, 255, 100, 1)
    adaptive_block = st.slider("é©å¿œï¼ˆè¿‘å‚ï¼‰ãƒ–ãƒ­ãƒƒã‚¯ã‚µã‚¤ã‚º", 3, 101, 31, 2)
    adaptive_C = st.slider("é©å¿œã—ãã„å€¤ C", -20, 20, 0, 1)

    st.subheader("ãƒ¢ãƒ«ãƒ•ã‚©ãƒ­ã‚¸ï¼ˆäºŒå€¤å¾Œå‡¦ç†ï¼‰")
    open_ksize = st.select_slider("Open ã‚«ãƒ¼ãƒãƒ«", options=[0, 1, 2, 3, 4, 5, 6, 7], value=3)
    open_iter = st.slider("Open å›æ•°", 0, 5, 1, 1)
    close_ksize = st.select_slider("Close ã‚«ãƒ¼ãƒãƒ«", options=[0, 1, 2, 3, 4, 5, 6, 7], value=3)
    close_iter = st.slider("Close å›æ•°", 0, 5, 1, 1)

    st.subheader("è§£æå¯¾è±¡ï¼ˆé‡è¦ï¼‰")
    target_mode = st.selectbox(
        "ã©ã®é ˜åŸŸã‚’æ¤œå‡ºã™ã‚‹ï¼Ÿ",
        ["é»’é ˜åŸŸï¼ˆæ¬ é™¥ï¼‰", "ç™½é ˜åŸŸï¼ˆææ–™/ç²’å­ï¼‰"],
        index=0
    )
    assume_material_is_largest = st.toggle(
        "ææ–™ã¯æœ€å¤§é€£çµæˆåˆ†ï¼ˆç™½ï¼‰ã¨ã¿ãªã™ï¼ˆæ¨å¥¨ï¼‰",
        value=True
    )

    st.subheader("é»’æ¬ é™¥ã®æ¤œå‡ºæ–¹å¼ï¼ˆé»’é ˜åŸŸãƒ¢ãƒ¼ãƒ‰æ™‚ï¼‰")
    defect_mode_black = st.selectbox(
        "æ¬ é™¥ï¼ˆé»’ï¼‰ã®æ¤œå‡ºæ–¹å¼",
        ["å…ƒç”»åƒã®æ·±ã„é»’ç‚¹ï¼ˆãƒ–ãƒ©ãƒƒã‚¯ãƒãƒƒãƒˆï¼‰", "äºŒå€¤ã®é»’ï¼ˆå†…éƒ¨ç©´ï¼‰"],
        index=0
    )

    st.subheader("ãƒ–ãƒ©ãƒƒã‚¯ãƒãƒƒãƒˆè¨­å®šï¼ˆæ·±ã„é»’ç‚¹æ–¹å¼ï¼‰")
    bh_use_preprocessed = st.toggle("å‰å‡¦ç†å¾Œç”»åƒï¼ˆCLAHE+Gaussianï¼‰ã‚’ä½¿ã†", value=True)
    bh_ksize = st.slider("ãƒ–ãƒ©ãƒƒã‚¯ãƒãƒƒãƒˆ ã‚«ãƒ¼ãƒãƒ«ã‚µã‚¤ã‚ºï¼ˆæ¬ é™¥ã‚ˆã‚Šå°‘ã—å¤§ããï¼‰", 3, 51, 11, 2)
    bh_thresh_mode = st.selectbox("ãƒ–ãƒ©ãƒƒã‚¯ãƒãƒƒãƒˆã®äºŒå€¤åŒ–", ["otsu", "manual"], index=1)
    bh_manual_thr = st.slider("ãƒ–ãƒ©ãƒƒã‚¯ãƒãƒƒãƒˆ æ‰‹å‹•ã—ãã„å€¤", 1, 100, 25, 1)
    bh_border_exclude = st.slider("ææ–™å¢ƒç•Œã‚’é™¤å¤–ã™ã‚‹å¹… [px]ï¼ˆç¸ã®å½æ¤œå‡ºå¯¾ç­–ï¼‰", 0, 30, 3, 1)

    st.subheader("æ¬ é™¥ãƒã‚¹ã‚¯ç”¨ å¾Œå‡¦ç†ï¼ˆãƒã‚¤ã‚ºé™¤å»ï¼‰")
    defect_open_ksize = st.select_slider("æ¬ é™¥Open ã‚«ãƒ¼ãƒãƒ«", options=[0, 1, 2, 3, 4, 5, 6, 7], value=0)
    defect_open_iter = st.slider("æ¬ é™¥Open å›æ•°", 0, 5, 0, 1)
    defect_close_ksize = st.select_slider("æ¬ é™¥Close ã‚«ãƒ¼ãƒãƒ«", options=[0, 1, 2, 3, 4, 5, 6, 7], value=0)
    defect_close_iter = st.slider("æ¬ é™¥Close å›æ•°", 0, 5, 0, 1)

    st.subheader("åˆ†é›¢ï¼ˆWatershedï¼‰")
    use_watershed = st.toggle("æ¥è§¦æ¬ é™¥/ç²’å­ã‚’åˆ†é›¢ã™ã‚‹ï¼ˆWatershedï¼‰", value=False)
    min_distance_px = st.slider("å±€æ‰€æ¥µå¤§ã®æœ€å°è·é›¢ [px]", 1, 50, 10, 1)
    h_max = st.slider("h-maximaï¼ˆé«˜ã„ã»ã©ä¿å®ˆçš„ï¼‰", 0.0, 10.0, 1.0, 0.1)

    st.subheader("ãƒ•ã‚£ãƒ«ã‚¿")
    exclude_largest = st.toggle("æœ€å¤§é€£çµæˆåˆ†ã‚’é™¤å¤–ï¼ˆé€šå¸¸ã¯OFFæ¨å¥¨ï¼‰", value=False)
    min_area_px = st.slider("æœ€å°é¢ç© [pxÂ²]ï¼ˆå°ãƒã‚¤ã‚ºé™¤å»ï¼‰", 0, 5000, 10, 5)
    min_area_um2 = st.number_input("æœ€å°é¢ç© [Î¼mÂ²]ï¼ˆ0=ç„¡åŠ¹ï¼‰", min_value=0.0, value=0.0, step=1.0)

    st.subheader("ã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤ï¼ˆè¼ªéƒ­å¼·èª¿ï¼‰")
    aspect_low = st.slider("ã‚¢ã‚¹ãƒšã‚¯ãƒˆæ¯” å¢ƒç•Œ1ï¼ˆç·‘â†’é»„ï¼‰", 1.0, 5.0, 2.0, 0.1)
    aspect_high = st.slider("ã‚¢ã‚¹ãƒšã‚¯ãƒˆæ¯” å¢ƒç•Œ2ï¼ˆé»„â†’èµ¤ï¼‰", 1.0, 10.0, 3.0, 0.1)
    show_id = st.toggle("IDè¡¨ç¤º", value=True)

    draw_red_contour = st.toggle("è¼ªéƒ­ã‚’èµ¤ã§æç”»", value=True)
    contour_thickness = st.slider("è¼ªéƒ­ã®å¤ªã•", 1, 8, 3, 1)
    contour_only = st.toggle("è¼ªéƒ­ã®ã¿ï¼ˆå¡—ã‚Šã¤ã¶ã—ç„¡ã—ï¼‰", value=True)
    fill_alpha = st.slider("å¡—ã‚Šã¤ã¶ã—é€æ˜åº¦", 0.0, 0.8, 0.25, 0.05)

    st.markdown("---")
    st.caption(
        "ğŸ’¡ æ·±ã„é»’ç‚¹ï¼ˆç©ºéš™ï¼‰ç‹™ã„ã®æ¨å¥¨ï¼š\n"
        "- è§£æå¯¾è±¡=é»’é ˜åŸŸï¼ˆæ¬ é™¥ï¼‰\n"
        "- æ¬ é™¥æ–¹å¼=å…ƒç”»åƒã®æ·±ã„é»’ç‚¹ï¼ˆãƒ–ãƒ©ãƒƒã‚¯ãƒãƒƒãƒˆï¼‰\n"
        "- ã‚«ãƒ¼ãƒãƒ«ã‚µã‚¤ã‚º=æ¬ é™¥å¾„ã‚ˆã‚Šå°‘ã—å¤§ãã‚\n"
        "- æ‰‹å‹•ã—ãã„å€¤ã‚’ä¸Šã’ã‚‹ã¨ã€ã‚ˆã‚Šæ·±ã„é»’ã€ã ã‘ã«çµã‚Œã¾ã™\n"
        "- æ¬ é™¥ç‡(Aæ¡ˆ)=æ¬ é™¥ç·é¢ç©/ææ–™é¢ç©(%)"
    )

st.markdown("### å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«")
uploaded_files = st.file_uploader(
    "å˜ä¸€ã¾ãŸã¯è¤‡æ•°ã®ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã€ã¾ãŸã¯ ZIPï¼ˆç”»åƒå…¥ã‚Šï¼‰ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚",
    type=["png", "jpg", "jpeg", "tif", "tiff", "bmp", "zip"],
    accept_multiple_files=True
)

# =========================================================
# å‡¦ç†æœ¬ä½“
# =========================================================
if uploaded_files:
    to_process: List[Tuple[str, bytes]] = []
    for f in uploaded_files:
        if f.name.lower().endswith(".zip"):
            with zipfile.ZipFile(io.BytesIO(f.read())) as zf:
                for info in zf.infolist():
                    if info.is_dir():
                        continue
                    ext = os.path.splitext(info.filename.lower())[-1]
                    if ext in [".png", ".jpg", ".jpeg", ".tif", ".tiff", ".bmp"]:
                        to_process.append((info.filename, zf.read(info)))
        else:
            to_process.append((f.name, f.read()))

    results: List[pd.DataFrame] = []
    overlays: Dict[str, np.ndarray] = {}
    previews: Dict[str, Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]] = {}
    summaries: List[Dict[str, float]] = []

    progress = st.progress(0)
    for idx, (name, bts) in enumerate(to_process, start=1):
        try:
            df, img_gray, bin_clean, bin_target, debug_bh, overlay_img = process_one_image(
                name, bts, um_per_px,
                method, manual_thresh, adaptive_block, adaptive_C,
                clahe_clip, gauss_ksize, gauss_sigma,
                open_ksize, open_iter, close_ksize, close_iter,
                defect_open_ksize, defect_open_iter, defect_close_ksize, defect_close_iter,
                target_mode, assume_material_is_largest,
                defect_mode_black,
                bh_use_preprocessed, bh_ksize, bh_thresh_mode, bh_manual_thr, bh_border_exclude,
                use_watershed, min_distance_px, h_max,
                exclude_largest, min_area_px, min_area_um2,
                (aspect_low, aspect_high), show_id,
                fill_alpha, draw_red_contour, contour_thickness, contour_only
            )

            overlays[name] = overlay_img
            previews[name] = (img_gray, bin_clean, bin_target, debug_bh)

            if not df.empty:
                results.append(df)

            # æ¬ é™¥ç‡ã‚µãƒãƒªãƒ¼ï¼ˆAæ¡ˆï¼‰
            defect_mask_for_ratio = bin_target if target_mode == "é»’é ˜åŸŸï¼ˆæ¬ é™¥ï¼‰" else np.zeros_like(bin_clean)
            stats = compute_area_stats_A(
                bin_clean_u8=bin_clean,
                defect_mask_u8=defect_mask_for_ratio,
                um_per_px=um_per_px,
                assume_material_is_largest=assume_material_is_largest
            )
            stats.update({
                "source": name,
                "target_mode": target_mode,
                "defect_mode": defect_mode_black if target_mode == "é»’é ˜åŸŸï¼ˆæ¬ é™¥ï¼‰" else "-"
            })
            summaries.append(stats)

        except Exception as e:
            st.error(f"ã€{name}ã€‘ã®è§£æã§ã‚¨ãƒ©ãƒ¼ï¼š{e}")

        progress.progress(int(100 * idx / max(1, len(to_process))))

    df_all = pd.concat(results, ignore_index=True) if len(results) > 0 else pd.DataFrame()
    df_sum = pd.DataFrame(summaries) if len(summaries) > 0 else pd.DataFrame()

    # --- ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ ---
    st.markdown("### å¯è¦–åŒ–ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼")
    show_blackhat = (target_mode == "é»’é ˜åŸŸï¼ˆæ¬ é™¥ï¼‰" and defect_mode_black == "å…ƒç”»åƒã®æ·±ã„é»’ç‚¹ï¼ˆãƒ–ãƒ©ãƒƒã‚¯ãƒãƒƒãƒˆï¼‰")

    for name, (img_gray, bin_clean, bin_target, debug_bh) in previews.items():
        st.markdown(f"**{name}**")
        if show_blackhat:
            cols = st.columns(5)
            with cols[0]:
                st.image(img_gray, caption="å…ƒç”»åƒ", use_container_width=True, clamp=True)
            with cols[1]:
                st.image(bin_clean, caption="äºŒå€¤ï¼ˆå¾Œå‡¦ç†è¾¼ã¿ï¼‰", use_container_width=True, clamp=True)
            with cols[2]:
                st.image(debug_bh, caption="ãƒ–ãƒ©ãƒƒã‚¯ãƒãƒƒãƒˆå¼·èª¿ï¼ˆROIï¼‰", use_container_width=True, clamp=True)
            with cols[3]:
                st.image(bin_target, caption="æ¤œå‡ºå¯¾è±¡ãƒã‚¹ã‚¯ï¼ˆæ¬ é™¥ï¼‰", use_container_width=True, clamp=True)
            with cols[4]:
                st.image(cv2.cvtColor(overlays[name], cv2.COLOR_BGR2RGB),
                         caption="ã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤ï¼ˆè¼ªéƒ­=èµ¤ï¼‰",
                         use_container_width=True, clamp=True)
        else:
            cols = st.columns(4)
            with cols[0]:
                st.image(img_gray, caption="å…ƒç”»åƒ", use_container_width=True, clamp=True)
            with cols[1]:
                st.image(bin_clean, caption="äºŒå€¤ï¼ˆå¾Œå‡¦ç†è¾¼ã¿ï¼‰", use_container_width=True, clamp=True)
            with cols[2]:
                st.image(bin_target, caption=f"æ¤œå‡ºå¯¾è±¡ãƒã‚¹ã‚¯ï¼š{target_mode}", use_container_width=True, clamp=True)
            with cols[3]:
                st.image(cv2.cvtColor(overlays[name], cv2.COLOR_BGR2RGB),
                         caption="ã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤ï¼ˆè¼ªéƒ­=èµ¤ï¼‰",
                         use_container_width=True, clamp=True)

    # --- æ¬ é™¥ç‡ã‚µãƒãƒªãƒ¼ ---
    if not df_sum.empty:
        st.markdown("### æ¬ é™¥ç‡ã‚µãƒãƒªãƒ¼ï¼ˆAæ¡ˆï¼šæ¬ é™¥ç·é¢ç© / ææ–™é¢ç©ï¼‰")
        df_sum_disp = df_sum[[
            "source", "target_mode", "defect_mode",
            "material_area_um2", "defect_area_um2", "defect_ratio_percent",
            "material_area_px", "defect_area_px"
        ]].copy()

        df_sum_disp.rename(columns={
            "material_area_um2": "ææ–™é¢ç© [Î¼mÂ²]",
            "defect_area_um2": "æ¬ é™¥ç·é¢ç© [Î¼mÂ²]",
            "defect_ratio_percent": "æ¬ é™¥ç‡ [%]ï¼ˆæ¬ é™¥/ææ–™ï¼‰",
            "material_area_px": "ææ–™é¢ç© [pxÂ²]",
            "defect_area_px": "æ¬ é™¥ç·é¢ç© [pxÂ²]",
        }, inplace=True)

        df_sum_disp["ææ–™é¢ç© [Î¼mÂ²]"] = df_sum_disp["ææ–™é¢ç© [Î¼mÂ²]"].round(2)
        df_sum_disp["æ¬ é™¥ç·é¢ç© [Î¼mÂ²]"] = df_sum_disp["æ¬ é™¥ç·é¢ç© [Î¼mÂ²]"].round(2)
        df_sum_disp["æ¬ é™¥ç‡ [%]ï¼ˆæ¬ é™¥/ææ–™ï¼‰"] = df_sum_disp["æ¬ é™¥ç‡ [%]ï¼ˆæ¬ é™¥/ææ–™ï¼‰"].round(4)

        st.dataframe(df_sum_disp, use_container_width=True)

        sum_csv = df_sum_disp.to_csv(index=False).encode("utf-8-sig")
        st.download_button(
            "ğŸ“¥ æ¬ é™¥ç‡ã‚µãƒãƒªãƒ¼CSVã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
            data=sum_csv,
            file_name="defect_area_ratio_summary_A.csv",
            mime="text/csv"
        )

    # --- ç²’å­/æ¬ é™¥ ç‰¹æ€§CSV ---
    if not df_all.empty:
        st.markdown("### ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆï¼ˆæ¬ é™¥/ç²’å­ ç‰¹æ€§ï¼‰")
        csv_bytes = df_all.to_csv(index=False).encode("utf-8-sig")
        st.download_button(
            "ğŸ“¥ æ¬ é™¥/ç²’å­ ç‰¹æ€§CSVã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
            data=csv_bytes,
            file_name="grain_or_defect_metrics.csv",
            mime="text/csv"
        )

    # --- ã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤ZIP ---
    with tempfile.TemporaryDirectory() as tmpd:
        zip_path = os.path.join(tmpd, "overlays.zip")
        with zipfile.ZipFile(zip_path, "w", compression=zipfile.ZIP_DEFLATED) as zf:
            for name, img in overlays.items():
                out_name = os.path.splitext(os.path.basename(name))[0] + "_overlay.png"
                _, buf = cv2.imencode(".png", img)
                zf.writestr(out_name, buf.tobytes())
        with open(zip_path, "rb") as fz:
            st.download_button(
                "ğŸ–¼ï¸ æ³¨é‡ˆç”»åƒï¼ˆZIPï¼‰ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                data=fz.read(),
                file_name="overlays.zip",
                mime="application/zip"
            )

    # --- çµ±è¨ˆå¯è¦–åŒ– ---
    if not df_all.empty:
        st.markdown("### çµ±è¨ˆå¯è¦–åŒ–ï¼ˆå½¢çŠ¶æŒ‡æ¨™ï¼‰")
        plot_distributions(df_all, ["equiv_diam_um", "aspect_ratio", "circularity"], group="source")

else:
    st.info("å·¦ä¸‹ã® **[Browse files]** ã‹ã‚‰ç”»åƒã¾ãŸã¯ ZIP ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")
